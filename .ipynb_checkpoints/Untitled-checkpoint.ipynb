{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import stream,tree,metrics\n",
    "import utils\n",
    "import datetime\n",
    "from encoding import prefix_bin\n",
    "import csv\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = stream.iter_csv(\n",
    "            './data/bac_online_sample.csv',\n",
    "            )\n",
    "\n",
    "totallength = len(list(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = stream.iter_csv(\n",
    "            './data/bac_online_sample.csv',\n",
    "            drop=['END_DATE','ROLE','CLOSURE_TYPE','CLOSURE_REASON','WORKING_STATE','case_cost'],\n",
    "            target='outcome'\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Event stream entry**  \n",
    "----------  \n",
    "**Example 1)**  \n",
    "({'REQUEST_ID': '20175000168',  \n",
    "  'ACTIVITY': 'Service closure Request with network responsibility',  \n",
    "  'START_DATE': '2018-10-10 12:48:12.000',  \n",
    "  'CE_UO': '1'},  \n",
    " '')  \n",
    "   \n",
    "**Example 2)**  \n",
    "({'REQUEST_ID': '20175000168',  \n",
    "  'ACTIVITY': 'Request completed with account closure',  \n",
    "  'START_DATE': '2018-10-17 03:03:11.000',  \n",
    "  'CE_UO': 'BOF'},  \n",
    " 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_pair = {\n",
    "        'REQUEST_ID':'caseid',\n",
    "        'ACTIVITY':'activity',\n",
    "        'START_DATE':'ts',\n",
    "        'CE_UO':'resource'\n",
    "}\n",
    "\n",
    "case_dict ={}\n",
    "training_models ={}\n",
    "feature_matrix ={}\n",
    "casecount = 0\n",
    "rowcounter = 0\n",
    "resultdict ={}\n",
    "acc_dict ={}\n",
    "finishedcases = set()\n",
    "running_case = 0\n",
    "prediction_result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % Case finished: 0 Running case: 0\n",
      "7.68 % Case finished: 25 Running case: 124\n",
      "15.37 % Case finished: 114 Running case: 194\n",
      "23.05 % Case finished: 177 Running case: 281\n",
      "30.73 % Case finished: 264 Running case: 273\n",
      "38.41 % Case finished: 328 Running case: 297\n",
      "46.1 % Case finished: 413 Running case: 279\n",
      "53.78 % Case finished: 487 Running case: 280\n",
      "61.46 % Case finished: 574 Running case: 269\n",
      "69.15 % Case finished: 641 Running case: 289\n",
      "76.83 % Case finished: 717 Running case: 277\n",
      "84.51 % Case finished: 795 Running case: 275\n",
      "92.19 % Case finished: 863 Running case: 279\n",
      "99.88 % Case finished: 973 Running case: 218\n"
     ]
    }
   ],
   "source": [
    "for x,y in dataset:\n",
    "    if rowcounter%500 == 0:\n",
    "        print(round(rowcounter*100/totallength,2) ,'%', 'Case finished: %s'%(casecount), 'Running case: %s'%(running_case))\n",
    "    rowcounter +=1\n",
    "    # Event stream change dictionary keys\n",
    "    x = utils.dictkey_chg(x, key_pair)\n",
    "#     x['ts'] = x['ts'][:-4]\n",
    "    # Check label possible\n",
    "    # x = utils.set_label(x)\n",
    "    x['outcome'] =y \n",
    "    # Initialize case by prefix length\n",
    "    caseid = x['caseid']\n",
    "    outcome = x['outcome']\n",
    "#     progress = x['progress']\n",
    "\n",
    "    x.pop('caseid')\n",
    "    x.pop('outcome')\n",
    "#     x.pop('progress')\n",
    "\n",
    "    case_bin = prefix_bin(caseid, x)\n",
    "\n",
    "    if caseid not in list(case_dict.keys()):\n",
    "        case_bin.set_prefix_length(1)    \n",
    "        case_dict[caseid] = []\n",
    "        running_case +=1\n",
    "    elif caseid in finishedcases:\n",
    "        pass\n",
    "    else:\n",
    "        case_bin.set_prefix_length(len(case_dict[caseid])+1)\n",
    "        case_bin.set_prev_enc(case_dict[caseid][-1])\n",
    "    \n",
    "    # Encode event and cases and add to DB\n",
    "    case_bin.update_truelabel(outcome)   \n",
    "    case_bin.update_encoded()\n",
    "    case_dict[caseid].append(case_bin)\n",
    "    \n",
    "    # Detect label appeared case \n",
    "    if outcome != '' and caseid not in finishedcases:\n",
    "        finishedcases.add(caseid)\n",
    "        # Adding newly finished case to training set.    \n",
    "        casecount +=1\n",
    "        # Grace period to collect feature matrix\n",
    "        if casecount <200:\n",
    "            case_length = len(case_dict[caseid])\n",
    "            for prefix in range(1, case_length):\n",
    "                if 'prefix_%s'%(prefix+1) not in list(feature_matrix.keys()):\n",
    "                    feature_matrix['prefix_%s'%(prefix+1)]=set()\n",
    "                    # Initialize classifier and performance matrix and updating count\n",
    "                    training_models['prefix_%s'%(prefix+1)] = [tree.ExtremelyFastDecisionTreeClassifier(grace_period=100,split_criterion='info_gain'),metrics.Accuracy(), 0]\n",
    "                feature_list = list(case_dict[caseid][prefix].encoded.keys())\n",
    "                for x in feature_list: feature_matrix['prefix_%s'%(prefix+1)].add(x) \n",
    "            case_dict.pop(caseid)               \n",
    "\n",
    "        # Real training start\n",
    "        else:\n",
    "            # Modify encoded attributes of cases with feature matrix\n",
    "            case_length = len(case_dict[caseid])\n",
    "            if case_length >10:\n",
    "                case_length =10\n",
    "            y = outcome\n",
    "            for prefix in range(1, case_length):\n",
    "                case_dict[caseid][prefix].update_truelabel(y)\n",
    "                if case_dict[caseid][prefix].grace_updated == False:\n",
    "                    case_dict[caseid][prefix].encoded = utils.readjustment_training(case_dict[caseid][prefix].encoded, feature_matrix['prefix_%s'%(prefix+1)])\n",
    "                    case_dict[caseid][prefix].update_grace_status(True)\n",
    "                x = case_dict[caseid][prefix].encoded\n",
    "                model = training_models['prefix_%s'%(prefix+1)][0]\n",
    "                model.learn_one(x,y)\n",
    "                training_models['prefix_%s'%(prefix+1)][2] +=1\n",
    "                y_pred = model.predict_one(x)\n",
    "                training_models['prefix_%s'%(prefix+1)][1].update(y,y_pred)\n",
    "\n",
    "                for cases in list(case_dict.keys()):\n",
    "                    if len(case_dict[cases]) >prefix:\n",
    "                        if case_dict[cases][prefix].grace_updated ==False:\n",
    "                            case_dict[cases][prefix].encoded = utils.readjustment_training(case_dict[cases][prefix].encoded, feature_matrix['prefix_%s'%(prefix+1)])\n",
    "                            case_dict[cases][prefix].update_grace_status(True)\n",
    "                        x_test = case_dict[cases][prefix].encoded\n",
    "                        y_pred = model.predict_one(x_test)\n",
    "                        modelid,pred_value = copy.deepcopy(training_models['prefix_%s'%(prefix+1)][2]), copy.deepcopy(y_pred)\n",
    "                        case_dict[cases][prefix].update_prediction((modelid, pred_value))\n",
    "                        prediction_key = str(cases)+'_'+str(prefix)\n",
    "                        if prediction_key not in prediction_result.keys():\n",
    "                            prediction_result[prediction_key] = {}\n",
    "                            prediction_result[prediction_key][modelid] = (pred_value,time.time())\n",
    "                        else:\n",
    "                            prediction_result[prediction_key][modelid] = (pred_value,time.time())\n",
    "            copying = copy.deepcopy(case_dict[caseid])\n",
    "            resultdict[caseid] = copying\n",
    "            # case_dict[caseid] =[]\n",
    "            running_case -=1\n",
    "            for prefix in training_models.keys():\n",
    "                if prefix not in list(acc_dict.keys()):\n",
    "                    acc_dict[prefix]=[training_models[prefix][1].get()]\n",
    "                else:\n",
    "                    acc_dict[prefix].append(training_models[prefix][1].get())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for t in list(acc_dict.keys())[:9]:\n",
    "    plt.plot(acc_dict[t], label=str(t))\n",
    "    plt.legend(ncol=2,loc='lower right')\n",
    "plt.title('Accuracy update with finished case by prefix length')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Finished cases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix_2 4437\n",
      "prefix_3 3957\n",
      "prefix_4 3931\n",
      "prefix_5 3928\n",
      "prefix_6 3753\n",
      "prefix_7 3341\n",
      "prefix_8 356\n",
      "prefix_9 212\n",
      "prefix_10 34\n",
      "prefix_11 0\n",
      "prefix_12 0\n",
      "prefix_13 0\n"
     ]
    }
   ],
   "source": [
    "for m in training_models.keys():\n",
    "    print(m, training_models[m][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "[]\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "[]\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "[]\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "[]\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "[]\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['True']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "[]\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "[]\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['True']\n",
      "[]\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "[]\n",
      "['False']\n",
      "['False']\n",
      "['False']\n",
      "['False']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ea3f15cf302b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcase\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresultdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresultdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcase\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for case in resultdict.keys():\n",
    "    print(resultdict[case][-2].predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1612489033.7311432, 1612489033.7651408, 1612489033.7781408, 1612489033.7901404, 1612489033.8041406, 1612489033.8161418, 1612489033.8301418, 1612489033.8431418, 1612489033.856144, 1612489033.8801405]\n",
      "----------\n",
      "[1612489033.7401426, 1612489033.7671409, 1612489033.7791412, 1612489033.7921426, 1612489033.8061416, 1612489033.8181407, 1612489033.8321426, 1612489033.8451405, 1612489033.8581412, 1612489033.8831422]\n"
     ]
    }
   ],
   "source": [
    "# checklist= []\n",
    "# for t in sorted(prediction_result.keys()):\n",
    "# #     if int(t.split('_')[1]) >=6:\n",
    "#     checklist.append(t)\n",
    "#     print(t)\n",
    "print([x[1] for x in prediction_result['201711005290_2'].values()][:10])\n",
    "print('----------')\n",
    "print([x[1] for x in prediction_result['201711005290_3'].values()][:10])\n",
    "# for e in checklist[:10]:\n",
    "#     print(e,set(prediction_result[e].values()))\n",
    "# for e in sorted(prediction_result.keys())[-100:]:\n",
    "#     print(e,prediction_result[e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix_2\n",
      "Accuracy: 90.77%\n",
      "           False    True\n",
      "   False    1229      21\n",
      "    True     105      10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.98      0.95      1250\n",
      "        True       0.32      0.09      0.14       115\n",
      "\n",
      "    accuracy                           0.91      1365\n",
      "   macro avg       0.62      0.54      0.54      1365\n",
      "weighted avg       0.87      0.91      0.88      1365\n",
      "\n",
      "prefix_3\n",
      "Accuracy: 89.53%\n",
      "           False    True\n",
      "   False    1224      20\n",
      "    True     124       8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.98      0.94      1244\n",
      "        True       0.29      0.06      0.10       132\n",
      "\n",
      "    accuracy                           0.90      1376\n",
      "   macro avg       0.60      0.52      0.52      1376\n",
      "weighted avg       0.85      0.90      0.86      1376\n",
      "\n",
      "prefix_4\n",
      "Accuracy: 92.49%\n",
      "           False    True\n",
      "   False    1253      12\n",
      "    True      91      15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.99      0.96      1265\n",
      "        True       0.56      0.14      0.23       106\n",
      "\n",
      "    accuracy                           0.92      1371\n",
      "   macro avg       0.74      0.57      0.59      1371\n",
      "weighted avg       0.90      0.92      0.90      1371\n",
      "\n",
      "prefix_5\n",
      "Accuracy: 90.70%\n",
      "           False    True\n",
      "   False    1181      16\n",
      "    True     106       9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.99      0.95      1197\n",
      "        True       0.36      0.08      0.13       115\n",
      "\n",
      "    accuracy                           0.91      1312\n",
      "   macro avg       0.64      0.53      0.54      1312\n",
      "weighted avg       0.87      0.91      0.88      1312\n",
      "\n",
      "prefix_6\n",
      "Accuracy: 90.70%\n",
      "         False   True\n",
      "  False    983    111\n",
      "   True      0    100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.90      0.95      1094\n",
      "        True       0.47      1.00      0.64       100\n",
      "\n",
      "    accuracy                           0.91      1194\n",
      "   macro avg       0.74      0.95      0.79      1194\n",
      "weighted avg       0.96      0.91      0.92      1194\n",
      "\n",
      "prefix_7\n",
      "Accuracy: 66.89%\n",
      "         False   True\n",
      "  False    101      0\n",
      "   True     50      0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.67      1.00      0.80       101\n",
      "        True       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.67       151\n",
      "   macro avg       0.33      0.50      0.40       151\n",
      "weighted avg       0.45      0.67      0.54       151\n",
      "\n",
      "prefix_8\n",
      "Accuracy: 87.50%\n",
      "         False   True\n",
      "  False     54      2\n",
      "   True     10     30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.96      0.90        56\n",
      "        True       0.94      0.75      0.83        40\n",
      "\n",
      "    accuracy                           0.88        96\n",
      "   macro avg       0.89      0.86      0.87        96\n",
      "weighted avg       0.88      0.88      0.87        96\n",
      "\n",
      "prefix_9\n",
      "Accuracy: 95.83%\n",
      "         False   True\n",
      "  False     23      0\n",
      "   True      1      0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      1.00      0.98        23\n",
      "        True       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        24\n",
      "   macro avg       0.48      0.50      0.49        24\n",
      "weighted avg       0.92      0.96      0.94        24\n",
      "\n",
      "prefix_10\n",
      "Accuracy: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-02a0b3dd7f8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesttrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python3\\lib\\site-packages\\river\\metrics\\confusion.pyx\u001b[0m in \u001b[0;36mriver.metrics.confusion.ConfusionMatrix.__repr__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "for t in range(2,11):\n",
    "    testcases =[]\n",
    "    testpred = []\n",
    "    testtrue = []\n",
    "\n",
    "    print('prefix_%s'%(t))\n",
    "    for cases in (np.random.choice(list(resultdict.keys()), 1500)):\n",
    "        if len(resultdict[cases])>t:\n",
    "            y_pred = training_models['prefix_%s'%(t+1)][0].predict_one(resultdict[cases][t].encoded)\n",
    "            testpred.append(y_pred)\n",
    "            testtrue.append(resultdict[cases][t].true_label)\n",
    "    metric = metrics.Accuracy()\n",
    "    cm = metrics.ConfusionMatrix()\n",
    "    for yt,yp in zip(testtrue,testpred):\n",
    "        metric = metric.update(yt,yp)\n",
    "        cm = cm.update(yt,yp)\n",
    "    print(metric)\n",
    "    print(cm)\n",
    "    print(classification_report(testtrue,testpred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
