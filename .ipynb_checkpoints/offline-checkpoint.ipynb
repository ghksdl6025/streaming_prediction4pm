{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import utils\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_prefix(df,prefix):\n",
    "    '''\n",
    "    Filter case by prefix length\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Assigned dataframe to slice by prefix length\n",
    "    \n",
    "    prefix : int\n",
    "        Prefix length to slice to cases in fixed length\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Return dataframe with sliced cases\n",
    "    '''\n",
    "    df['ts'] = pd.to_datetime(df['ts'])\n",
    "    groups = df.groupby('caseid')\n",
    "    encoded_df=[]\n",
    "    for case,group in groups: \n",
    "        group = group.reset_index(drop=True)\n",
    "        if len(group)>prefix:\n",
    "            group = group.loc[:prefix-1,:]\n",
    "            encoded_df.append(group)\n",
    "    return pd.concat(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregation_encoding(df, prefix):\n",
    "    '''\n",
    "    Aggregation encoding\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Assigned dataframe to encode for outcome prediction\n",
    "    \n",
    "    prefix : int\n",
    "        Prefix length to slice to cases in fixed length\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Return dataframe encoded in aggregation method\n",
    "    '''\n",
    "    df = filter_by_prefix(df,prefix)\n",
    "    df['ts'] = pd.to_datetime(df['ts'])\n",
    "    groups = df.groupby('caseid')\n",
    "    encoded_df=[]\n",
    "    for case,group in groups: \n",
    "        group = group.reset_index(drop=True)\n",
    "        outcome = set(group['outcome']).pop()\n",
    "        cumdurationlist = [(x - list(group['ts'])[0]).total_seconds() for x in list(group['ts'])]\n",
    "        case_time_outcome = {'caseid':case, 'ts':np.mean(cumdurationlist),'outcome':outcome}\n",
    "        activity_count = {x: list(group['activity']).count(x) for x in set(group['activity'])}\n",
    "        resource_count = {x: list(group['resource']).count(x) for x in set(group['resource'])}\n",
    "\n",
    "        case_time_outcome.update(activity_count)\n",
    "        case_time_outcome.update(resource_count)\n",
    "        dfk = pd.DataFrame.from_dict([case_time_outcome])\n",
    "        encoded_df.append(dfk)\n",
    "    concated_df = pd.concat(encoded_df)\n",
    "    concated_df = concated_df.fillna(0)\n",
    "    return concated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexbase_encoding(df, prefix):\n",
    "    '''\n",
    "    Indexbase encoding\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Assigned dataframe to encode for outcome prediction\n",
    "    \n",
    "    prefix : int\n",
    "        Prefix length to slice to cases in fixed length\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Return dataframe encoded in indexbase method\n",
    "    '''\n",
    "    df = filter_by_prefix(df,prefix)\n",
    "    df['ts'] = pd.to_datetime(df['ts'])\n",
    "    groups = df.groupby('caseid')\n",
    "    encoded_df=[]\n",
    "    for case,group in groups: \n",
    "        activitylist = list(group['activity'])\n",
    "        resourcelist = list(group['resource'])\n",
    "        group = group.reset_index(drop=True)\n",
    "        outcome = set(group['outcome']).pop()\n",
    "        cumdurationlist = [(x - list(group['ts'])[0]).total_seconds() for x in list(group['ts'])]\n",
    "        cumduration_index ={'Cumduration_'+str(x+1): cumdurationlist[x] for x in range(len(cumdurationlist))}\n",
    "        case_outcome = {'caseid':case, 'outcome':outcome}\n",
    "        activity_index = {'activity_'+str(x+1)+'_'+activitylist[x]: 1 for x in range(len(activitylist))}\n",
    "        resource_index = {'resource_'+str(x+1)+'_'+str(resourcelist[x]): 1 for x in range(len(resourcelist))}\n",
    "        case_outcome.update(cumduration_index)\n",
    "        case_outcome.update(activity_index)\n",
    "        case_outcome.update(resource_index)\n",
    "        dfk = pd.DataFrame.from_dict([case_outcome])\n",
    "        encoded_df.append(dfk)\n",
    "    concated_df = pd.concat(encoded_df)\n",
    "    concated_df = concated_df.fillna(0)\n",
    "    return concated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/bac_offline_small.csv')\n",
    "df['START_DATE'] = pd.to_datetime(df['START_DATE'])\n",
    "df = df.rename(columns={'REQUEST_ID':'caseid','ACTIVITY':'activity','START_DATE':'ts','CE_UO':'resource'})\n",
    "df = df.loc[:,['caseid','activity','ts','resource','outcome']]\n",
    "groups = df.groupby('caseid')\n",
    "reconcatenate =[]\n",
    "dfn = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf5 = aggregation_encoding(dfn,5)\n",
    "idf5 = indexbase_encoding(dfn,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf6 = aggregation_encoding(dfn,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf7 = aggregation_encoding(dfn,7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf8 = aggregation_encoding(dfn,8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf9 = aggregation_encoding(dfn,9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf10 = aggregation_encoding(dfn,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf2 = aggregation_encoding(dfn,2)\n",
    "adf3 = aggregation_encoding(dfn,3)\n",
    "adf4 = aggregation_encoding(dfn,4)\n",
    "adf11 = aggregation_encoding(dfn,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAC aggregation encoding with prefix length 2\n",
      "BAC aggregation encoding with prefix length 3\n",
      "BAC aggregation encoding with prefix length 4\n",
      "BAC aggregation encoding with prefix length 5\n",
      "BAC aggregation encoding with prefix length 6\n",
      "BAC aggregation encoding with prefix length 7\n",
      "BAC aggregation encoding with prefix length 8\n",
      "BAC aggregation encoding with prefix length 9\n",
      "BAC aggregation encoding with prefix length 10\n",
      "BAC aggregation encoding with prefix length 11\n"
     ]
    }
   ],
   "source": [
    "adflist = [adf2,adf3,adf4,adf5,adf6,adf7,adf8,adf9,adf10,adf11]\n",
    "prefixlist= list(range(2,12))\n",
    "acc_dict= {}\n",
    "for pos,prefix in enumerate(adflist):\n",
    "    print('BAC aggregation encoding with prefix length %s'%(prefixlist[pos]))\n",
    "    y = prefix['outcome']\n",
    "    x =prefix.drop(columns=['outcome','caseid'],axis=1)\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.3)\n",
    "\n",
    "    # Deicision tree result\n",
    "    dt = DecisionTreeClassifier(criterion='entropy').fit(x_train,y_train)\n",
    "    y_pred = dt.predict(x_test)\n",
    "    acc_dict['prefix_%s'%(str(prefixlist[pos]))] =  accuracy_score(y_test,y_pred)\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "x = list(acc_dict.keys())\n",
    "y = [acc_dict[x] for x in acc_dict.keys()]\n",
    "with open('./result/noneg_off_dt_acc.pkl','wb') as f:\n",
    "    pkl.dump([x,y],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAC aggregation encoding with prefix length 2\n",
      "BAC aggregation encoding with prefix length 3\n",
      "BAC aggregation encoding with prefix length 4\n",
      "BAC aggregation encoding with prefix length 5\n",
      "BAC aggregation encoding with prefix length 6\n",
      "BAC aggregation encoding with prefix length 7\n",
      "BAC aggregation encoding with prefix length 8\n",
      "BAC aggregation encoding with prefix length 9\n",
      "BAC aggregation encoding with prefix length 10\n",
      "BAC aggregation encoding with prefix length 11\n",
      "{'prefix_2': 0.9077123050259965, 'prefix_3': 0.9246187363834423, 'prefix_4': 0.9232446576537288, 'prefix_5': 0.9227251943301326, 'prefix_6': 0.9144905273937532, 'prefix_7': 0.86, 'prefix_8': 0.68, 'prefix_9': 0.9230769230769231, 'prefix_10': 0.6666666666666666, 'prefix_11': 1.0}\n"
     ]
    }
   ],
   "source": [
    "adflist = [adf2,adf3,adf4,adf5,adf6,adf7,adf8,adf9,adf10,adf11]\n",
    "prefixlist= list(range(2,12))\n",
    "acc_dict= {}\n",
    "for pos,prefix in enumerate(adflist):\n",
    "    print('BAC aggregation encoding with prefix length %s'%(prefixlist[pos]))\n",
    "    y = prefix['outcome']\n",
    "    x =prefix.drop(columns=['outcome','caseid'],axis=1)\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.3)\n",
    "\n",
    "    # Deicision tree result\n",
    "    dt = RandomForestClassifier(criterion='entropy').fit(x_train,y_train)\n",
    "    y_pred = dt.predict(x_test)\n",
    "    acc_dict['prefix_%s'%(str(prefixlist[pos]))] =  accuracy_score(y_test,y_pred)\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "x = list(acc_dict.keys())\n",
    "y = [acc_dict[x] for x in acc_dict.keys()]\n",
    "print(acc_dict)\n",
    "with open('./result/noneg_off_rf_acc.pkl','wb') as f:\n",
    "    pkl.dump([x,y],f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
