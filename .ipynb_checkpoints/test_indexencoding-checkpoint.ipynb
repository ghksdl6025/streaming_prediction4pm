{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import stream,tree,metrics\n",
    "import utils\n",
    "import datetime\n",
    "from encoding import prefix_bin\n",
    "import csv\n",
    "import copy\n",
    "import time\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = stream.iter_csv(\n",
    "            './data/bac_online_small.csv',\n",
    "            )\n",
    "\n",
    "totallength = len(list(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = stream.iter_csv(\n",
    "            './data/bac_online_small.csv',\n",
    "            drop=['END_DATE','ROLE','CLOSURE_TYPE','CLOSURE_REASON','WORKING_STATE','case_cost'],\n",
    "            target='outcome'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_pair = {\n",
    "        'REQUEST_ID':'caseid',\n",
    "        'ACTIVITY':'activity',\n",
    "        'START_DATE':'ts',\n",
    "        'CE_UO':'resource'\n",
    "}\n",
    "\n",
    "# General streaming process prediction setting\n",
    "case_dict ={}\n",
    "training_models ={}\n",
    "feature_matrix ={}\n",
    "casecount = 0\n",
    "rowcounter = 0\n",
    "resultdict ={}\n",
    "acc_dict ={}\n",
    "running_case = 0\n",
    "prediction_result = {}\n",
    "graceperiod_finish=0\n",
    "finishedcases = set()\n",
    "usedingrace = set()\n",
    "graceperiod_training = {}\n",
    "\n",
    "# Experiment settings\n",
    "encoding = 'Index-base'\n",
    "cat_attrs= ['activity','resource']\n",
    "con_attrs= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % Case finished: 0\n",
      "0.89 % Case finished: 6\n",
      "1.79 % Case finished: 7\n",
      "2.68 % Case finished: 7\n",
      "3.57 % Case finished: 7\n",
      "4.46 % Case finished: 7\n",
      "5.36 % Case finished: 7\n",
      "6.25 % Case finished: 70\n",
      "7.14 % Case finished: 94\n",
      "8.04 % Case finished: 124\n"
     ]
    }
   ],
   "source": [
    "for x,y in dataset:\n",
    "    if rowcounter%500 == 0:\n",
    "        print(round(rowcounter*100/totallength,2) ,'%', 'Case finished: %s'%(casecount))\n",
    "    rowcounter +=1\n",
    "    # Event stream change dictionary keys\n",
    "    x = utils.dictkey_chg(x, key_pair)\n",
    "#     x['ts'] = x['ts'][:-4]\n",
    "    # Check label possible\n",
    "    # x = utils.set_label(x)\n",
    "    x['outcome'] =y \n",
    "    # Initialize case by prefix length\n",
    "    caseid = x['caseid']\n",
    "    outcome = x['outcome']\n",
    "#     progress = x['progress']\n",
    "\n",
    "    x.pop('caseid')\n",
    "    x.pop('outcome')\n",
    "    \n",
    "#     x.pop('progress')\n",
    "\n",
    "    case_bin = prefix_bin(caseid, x)\n",
    "\n",
    "    if caseid not in list(case_dict.keys()):\n",
    "        case_bin.set_prefix_length(1)    \n",
    "        case_dict[caseid] = []\n",
    "    elif caseid in finishedcases:\n",
    "        pass\n",
    "    else:\n",
    "        case_bin.set_prefix_length(len(case_dict[caseid])+1)\n",
    "        case_bin.set_prev_enc(case_dict[caseid][-1])\n",
    "    \n",
    "    # Encode event and cases and add to DB\n",
    "    case_bin.update_truelabel(outcome)   \n",
    "    case_bin.update_encoded(catattrs=cat_attrs, enctype = encoding)\n",
    "    ts = case_bin.event['ts']\n",
    "    case_dict[caseid].append(case_bin)\n",
    "    usedingrace.add(caseid)\n",
    "    \n",
    "    # Detect label appeared case \n",
    "    if outcome != '' and caseid not in finishedcases:\n",
    "        finishedcases.add(caseid)\n",
    "        \n",
    "        # Adding newly finished case to training set.    \n",
    "        casecount +=1\n",
    "        \n",
    "        # Grace period to collect feature matrix\n",
    "        if casecount <=200:\n",
    "            case_length = len(case_dict[caseid])\n",
    "            for prefix in range(1, case_length):\n",
    "                if 'prefix_%s'%(prefix+1) not in list(feature_matrix.keys()):\n",
    "                    feature_matrix['prefix_%s'%(prefix+1)]=set()\n",
    "                    # Initialize classifier and performance matrix and updating count\n",
    "                    training_models['prefix_%s'%(prefix+1)] = [tree.HoeffdingTreeClassifier(grace_period=100,split_criterion='info_gain'),metrics.Accuracy(), 0,0]\n",
    "                feature_list = list(case_dict[caseid][prefix].encoded.keys())\n",
    "                for x in feature_list: feature_matrix['prefix_%s'%(prefix+1)].add(x) \n",
    "            graceperiod_finish = case_dict[caseid][-1].event['ts']\n",
    "            for t in training_models.keys():\n",
    "                training_models[t][3] = graceperiod_finish\n",
    "            graceperiod_training[caseid] = case_dict.pop(caseid)            \n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'duration_1': 0, 'cumduration_1': 0, 'activity_1 Request created': 1, 'resource_1 242': 1, 'duration_2': 74.0, 'cumduration_2': 74.0, 'activity_2 Service closure Request with network responsibility': 1, 'resource_2 ': 1, 'duration_3': 2515988.0, 'cumduration_3': 2516062.0, 'activity_3 Authorization Requested': 1, 'resource_3 429': 1, 'duration_4': 319609.0, 'cumduration_4': 2835671.0, 'activity_4 Service closure Request with BO responsibility': 1, 'resource_4 BOF': 1}\n"
     ]
    }
   ],
   "source": [
    "# for t in case_dict:\n",
    "#     print(t, len(case_dict[t]))\n",
    "print(case_dict['201712001567'][3].encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'duration_1': 0, 'cumduration_1': 0, 'activity_1 Request created': 1, 'resource_1 6': 1, 'duration_2': 99.0, 'cumduration_2': 99.0, 'activity_2 Evaluating Request (NO registered letter)': 1, 'resource_2 7': 1, 'duration_3': 399.0, 'cumduration_3': 498.0, 'activity_3 Service closure Request with network responsibility': 1, 'resource_3 7': 1, 'duration_4': 395.0, 'cumduration_4': 893.0, 'activity_4 Service closure Request with BO responsibility': 1, 'resource_4 BOF': 1}\n",
      "['cumduration_2', 'cumduration_1', 'duration_1', 'duration_2', 'cumduration_2', 'duration_2', 'duration_1', 'cumduration_3', 'cumduration_1', 'duration_3', 'cumduration_2', 'cumduration_4', 'duration_4', 'duration_2', 'duration_1', 'cumduration_3', 'cumduration_1', 'duration_3', 'cumduration_2', 'cumduration_4', 'cumduration_5', 'duration_4', 'duration_2', 'duration_5', 'duration_1', 'cumduration_3', 'cumduration_1', 'duration_3', 'cumduration_2', 'cumduration_6', 'cumduration_4', 'cumduration_5', 'duration_4', 'duration_2', 'duration_5', 'duration_1', 'cumduration_3', 'duration_6', 'cumduration_1', 'duration_3', 'cumduration_2', 'cumduration_6', 'cumduration_4', 'cumduration_7', 'cumduration_5', 'duration_4', 'duration_2', 'duration_7', 'duration_5', 'duration_1', 'cumduration_3', 'duration_6', 'cumduration_1', 'duration_3', 'duration_6', 'cumduration_2', 'cumduration_7', 'cumduration_1', 'cumduration_8', 'cumduration_5', 'duration_8', 'duration_1', 'duration_4', 'cumduration_6', 'cumduration_3', 'duration_2', 'cumduration_4', 'duration_3', 'duration_7', 'duration_5', 'duration_6', 'cumduration_2', 'cumduration_7', 'cumduration_1', 'cumduration_8', 'cumduration_5', 'duration_8', 'duration_1', 'duration_9', 'duration_4', 'cumduration_6', 'cumduration_3', 'cumduration_9', 'duration_2', 'cumduration_4', 'duration_3', 'duration_7', 'duration_5', 'cumduration_3', 'duration_3', 'cumduration_8', 'cumduration_5', 'duration_8', 'cumduration_10', 'duration_1', 'duration_9', 'duration_4', 'duration_10', 'duration_6', 'cumduration_2', 'cumduration_7', 'cumduration_9', 'duration_2', 'cumduration_1', 'cumduration_4', 'duration_7', 'cumduration_6', 'duration_5', 'cumduration_3', 'duration_3', 'cumduration_8', 'cumduration_5', 'duration_8', 'cumduration_11', 'cumduration_10', 'duration_1', 'duration_9', 'duration_4', 'duration_10', 'duration_6', 'cumduration_2', 'cumduration_7', 'cumduration_9', 'duration_2', 'duration_11', 'cumduration_1', 'cumduration_4', 'duration_7', 'cumduration_6', 'duration_5']\n"
     ]
    }
   ],
   "source": [
    "print(len(graceperiod_training))\n",
    "print(graceperiod_training['20175001550'][3].encoded)\n",
    "\n",
    "\n",
    "for t in feature_matrix:\n",
    "    for encoding_item in feature_matrix[t]:\n",
    "        if encoding_item.split('_')[0] not in cat_attrs:\n",
    "            con_attrs.append(encoding_item)\n",
    "print(con_attrs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
