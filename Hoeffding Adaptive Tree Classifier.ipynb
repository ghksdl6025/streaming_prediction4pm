{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import stream,tree,metrics\n",
    "import utils\n",
    "import datetime\n",
    "from encoding import prefix_bin\n",
    "import csv\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = stream.iter_csv(\n",
    "            './data/bac_online_small.csv',\n",
    "            )\n",
    "\n",
    "totallength = len(list(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = stream.iter_csv(\n",
    "            './data/bac_online_small.csv',\n",
    "            drop=['END_DATE','ROLE','CLOSURE_TYPE','CLOSURE_REASON','WORKING_STATE','case_cost'],\n",
    "            target='outcome'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_pair = {\n",
    "        'REQUEST_ID':'caseid',\n",
    "        'ACTIVITY':'activity',\n",
    "        'START_DATE':'ts',\n",
    "        'CE_UO':'resource'\n",
    "}\n",
    "\n",
    "case_dict ={}\n",
    "training_models ={}\n",
    "feature_matrix ={}\n",
    "casecount = 0\n",
    "rowcounter = 0\n",
    "resultdict ={}\n",
    "acc_dict ={}\n",
    "finishedcases = set()\n",
    "running_case = 0\n",
    "prediction_result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % Case finished: 0 Running case: 0\n",
      "1.64 % Case finished: 1 Running case: 166\n",
      "3.29 % Case finished: 1 Running case: 319\n",
      "4.93 % Case finished: 1 Running case: 437\n",
      "6.57 % Case finished: 39 Running case: 547\n",
      "8.21 % Case finished: 49 Running case: 597\n",
      "9.86 % Case finished: 203 Running case: 631\n",
      "11.5 % Case finished: 292 Running case: 610\n",
      "13.14 % Case finished: 386 Running case: 590\n",
      "14.79 % Case finished: 474 Running case: 575\n",
      "16.43 % Case finished: 572 Running case: 538\n",
      "18.07 % Case finished: 648 Running case: 531\n",
      "19.72 % Case finished: 755 Running case: 510\n",
      "21.36 % Case finished: 769 Running case: 613\n",
      "23.0 % Case finished: 794 Running case: 659\n",
      "24.64 % Case finished: 896 Running case: 612\n",
      "26.29 % Case finished: 1016 Running case: 543\n",
      "27.93 % Case finished: 1076 Running case: 567\n",
      "29.57 % Case finished: 1134 Running case: 581\n",
      "31.22 % Case finished: 1233 Running case: 530\n",
      "32.86 % Case finished: 1361 Running case: 457\n",
      "34.5 % Case finished: 1434 Running case: 450\n",
      "36.14 % Case finished: 1507 Running case: 493\n",
      "37.79 % Case finished: 1538 Running case: 580\n",
      "39.43 % Case finished: 1574 Running case: 620\n",
      "41.07 % Case finished: 1672 Running case: 587\n",
      "42.72 % Case finished: 1735 Running case: 596\n",
      "44.36 % Case finished: 1826 Running case: 582\n",
      "46.0 % Case finished: 1918 Running case: 549\n",
      "47.65 % Case finished: 2003 Running case: 536\n",
      "49.29 % Case finished: 2046 Running case: 556\n",
      "50.93 % Case finished: 2163 Running case: 498\n",
      "52.57 % Case finished: 2261 Running case: 505\n",
      "54.22 % Case finished: 2284 Running case: 574\n",
      "55.86 % Case finished: 2358 Running case: 566\n",
      "57.5 % Case finished: 2438 Running case: 558\n",
      "59.15 % Case finished: 2528 Running case: 542\n",
      "60.79 % Case finished: 2633 Running case: 515\n",
      "62.43 % Case finished: 2731 Running case: 474\n",
      "64.08 % Case finished: 2784 Running case: 506\n",
      "65.72 % Case finished: 2840 Running case: 525\n",
      "67.36 % Case finished: 2997 Running case: 432\n",
      "69.0 % Case finished: 3009 Running case: 556\n",
      "70.65 % Case finished: 3049 Running case: 614\n",
      "72.29 % Case finished: 3068 Running case: 659\n",
      "73.93 % Case finished: 3147 Running case: 627\n",
      "75.58 % Case finished: 3313 Running case: 508\n",
      "77.22 % Case finished: 3424 Running case: 481\n",
      "78.86 % Case finished: 3446 Running case: 543\n",
      "80.5 % Case finished: 3561 Running case: 498\n",
      "82.15 % Case finished: 3629 Running case: 518\n",
      "83.79 % Case finished: 3691 Running case: 514\n",
      "85.43 % Case finished: 3809 Running case: 451\n",
      "87.08 % Case finished: 3854 Running case: 474\n",
      "88.72 % Case finished: 3976 Running case: 447\n",
      "90.36 % Case finished: 3986 Running case: 548\n",
      "92.01 % Case finished: 4043 Running case: 548\n",
      "93.65 % Case finished: 4139 Running case: 498\n",
      "95.29 % Case finished: 4281 Running case: 401\n",
      "96.93 % Case finished: 4357 Running case: 390\n",
      "98.58 % Case finished: 4489 Running case: 315\n"
     ]
    }
   ],
   "source": [
    "for x,y in dataset:\n",
    "    if rowcounter%500 == 0:\n",
    "        print(round(rowcounter*100/totallength,2) ,'%', 'Case finished: %s'%(casecount), 'Running case: %s'%(running_case))\n",
    "    rowcounter +=1\n",
    "    # Event stream change dictionary keys\n",
    "    x = utils.dictkey_chg(x, key_pair)\n",
    "#     x['ts'] = x['ts'][:-4]\n",
    "    # Check label possible\n",
    "    # x = utils.set_label(x)\n",
    "    x['outcome'] =y \n",
    "    # Initialize case by prefix length\n",
    "    caseid = x['caseid']\n",
    "    outcome = x['outcome']\n",
    "#     progress = x['progress']\n",
    "\n",
    "    x.pop('caseid')\n",
    "    x.pop('outcome')\n",
    "#     x.pop('progress')\n",
    "\n",
    "    case_bin = prefix_bin(caseid, x)\n",
    "\n",
    "    if caseid not in list(case_dict.keys()):\n",
    "        case_bin.set_prefix_length(1)    \n",
    "        case_dict[caseid] = []\n",
    "        running_case +=1\n",
    "    elif caseid in finishedcases:\n",
    "        pass\n",
    "    else:\n",
    "        case_bin.set_prefix_length(len(case_dict[caseid])+1)\n",
    "        case_bin.set_prev_enc(case_dict[caseid][-1])\n",
    "    \n",
    "    # Encode event and cases and add to DB\n",
    "    case_bin.update_truelabel(outcome)   \n",
    "    case_bin.update_encoded()\n",
    "    case_dict[caseid].append(case_bin)\n",
    "    \n",
    "    # Detect label appeared case \n",
    "    if outcome != '' and caseid not in finishedcases:\n",
    "        finishedcases.add(caseid)\n",
    "        # Adding newly finished case to training set.    \n",
    "        casecount +=1\n",
    "        # Grace period to collect feature matrix\n",
    "        if casecount <200:\n",
    "            case_length = len(case_dict[caseid])\n",
    "            for prefix in range(1, case_length):\n",
    "                if 'prefix_%s'%(prefix+1) not in list(feature_matrix.keys()):\n",
    "                    feature_matrix['prefix_%s'%(prefix+1)]=set()\n",
    "                    # Initialize classifier and performance matrix and updating count\n",
    "                    training_models['prefix_%s'%(prefix+1)] = [tree.HoeffdingAdaptiveTreeClassifier(grace_period=100,split_criterion='info_gain'),metrics.Accuracy(), 0]\n",
    "                feature_list = list(case_dict[caseid][prefix].encoded.keys())\n",
    "                for x in feature_list: feature_matrix['prefix_%s'%(prefix+1)].add(x) \n",
    "            case_dict.pop(caseid)               \n",
    "\n",
    "        # Real training start\n",
    "        else:\n",
    "            # Modify encoded attributes of cases with feature matrix\n",
    "            case_length = len(case_dict[caseid])\n",
    "            if case_length >10:\n",
    "                case_length =10\n",
    "            y = outcome\n",
    "            for prefix in range(1, case_length):\n",
    "                case_dict[caseid][prefix].update_truelabel(y)\n",
    "                if case_dict[caseid][prefix].grace_updated == False:\n",
    "                    case_dict[caseid][prefix].encoded = utils.readjustment_training(case_dict[caseid][prefix].encoded, feature_matrix['prefix_%s'%(prefix+1)])\n",
    "                    case_dict[caseid][prefix].update_grace_status(True)\n",
    "                x = case_dict[caseid][prefix].encoded\n",
    "                model = training_models['prefix_%s'%(prefix+1)][0]\n",
    "                model.learn_one(x,y)\n",
    "                training_models['prefix_%s'%(prefix+1)][2] +=1\n",
    "                y_pred = model.predict_one(x)\n",
    "                training_models['prefix_%s'%(prefix+1)][1].update(y,y_pred)\n",
    "\n",
    "                for cases in list(case_dict.keys()):\n",
    "                    if len(case_dict[cases]) >prefix:\n",
    "                        if case_dict[cases][prefix].grace_updated ==False:\n",
    "                            case_dict[cases][prefix].encoded = utils.readjustment_training(case_dict[cases][prefix].encoded, feature_matrix['prefix_%s'%(prefix+1)])\n",
    "                            case_dict[cases][prefix].update_grace_status(True)\n",
    "                        x_test = case_dict[cases][prefix].encoded\n",
    "                        y_pred = model.predict_one(x_test)\n",
    "                        modelid,pred_value = copy.deepcopy(training_models['prefix_%s'%(prefix+1)][2]), copy.deepcopy(y_pred)\n",
    "                        case_dict[cases][prefix].update_prediction((modelid, pred_value))\n",
    "                        prediction_key = str(cases)+'_'+str(prefix+1)\n",
    "                        if str(cases)+'_'+str(prefix+2) not in prediction_result.keys():\n",
    "                            if prediction_key not in prediction_result.keys():\n",
    "                                prediction_result[prediction_key] = {}\n",
    "                                prediction_result[prediction_key][modelid] = (pred_value,time.time())\n",
    "                            else:\n",
    "                                prediction_result[prediction_key][modelid] = (pred_value,time.time())\n",
    "            copying = copy.deepcopy(case_dict[caseid])\n",
    "            resultdict[caseid] = copying\n",
    "            case_dict[caseid] =[]\n",
    "            running_case -=1\n",
    "            for prefix in training_models.keys():\n",
    "                if prefix not in list(acc_dict.keys()):\n",
    "                    acc_dict[prefix]=[training_models[prefix][1].get()]\n",
    "                else:\n",
    "                    acc_dict[prefix].append(training_models[prefix][1].get())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
