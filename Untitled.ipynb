{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exact-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import stream,tree,metrics\n",
    "import utils\n",
    "import datetime\n",
    "from encoding import prefix_bin\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stupid-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = stream.iter_csv(\n",
    "            './data/bpic2017.csv',\n",
    "            drop=['(case) Accepted', '(case) ApplicationID', '(case) CreditScore', '(case) FirstWithdrawalAmount',\n",
    "            '(case) MonthlyCost', '(case) NumberOfTerms', '(case) OfferedAmount', '(case) Selected',\n",
    "            'Action', 'EventID', 'EventOrigin', 'OfferID', 'lifecycle:transition']\n",
    "            )\n",
    "totallength = len(list(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "loaded-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = stream.iter_csv(\n",
    "            './data/bpic2017.csv',\n",
    "            drop=['(case) Accepted', '(case) ApplicationID', '(case) CreditScore', '(case) FirstWithdrawalAmount',\n",
    "            '(case) MonthlyCost', '(case) NumberOfTerms', '(case) OfferedAmount', '(case) Selected',\n",
    "            'Action', 'EventID', 'EventOrigin', 'OfferID', 'lifecycle:transition']\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "massive-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_pair = {\n",
    "    'Case ID' : 'caseid',\n",
    "    'Activity' : 'activity',\n",
    "    'Resource' : 'resource',\n",
    "    'Complete Timestamp' : 'ts'\n",
    "}\n",
    "\n",
    "case_dict ={}\n",
    "trainset_prefix ={}\n",
    "feature_matrix ={}\n",
    "casecount = 0\n",
    "rowcounter = 0\n",
    "resultdict ={}\n",
    "\n",
    "acc_dict ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fuzzy-roommate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % Case finished: 0\n",
      "4.46 % Case finished: 22\n",
      "8.92 % Case finished: 47\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2b31123957ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcase_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcaseid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainset_prefix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prefix_%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mtrainset_prefix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prefix_%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/river/tree/label_combination_hoeffding_tree.py\u001b[0m in \u001b[0;36mlearn_one\u001b[0;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \"\"\"\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0maux_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "for x,y in dataset:\n",
    "    if rowcounter%1000 == 0:\n",
    "        print(round(rowcounter*100/totallength,2) ,'%', 'Case finished: %s'%(casecount))\n",
    "    rowcounter +=1\n",
    "    # Event stream change dictionary keys\n",
    "    x = utils.dictkey_chg(x, key_pair)\n",
    "\n",
    "    # Event timestamp slice decimals\n",
    "    x['ts'] = x['ts'][:-4]\n",
    "\n",
    "    # Check label possible\n",
    "    x = utils.set_label(x)\n",
    "\n",
    "    # Initialize case by prefix length\n",
    "    caseid = x['caseid']\n",
    "    x.pop('caseid')\n",
    "    case_bin = prefix_bin(caseid, x)\n",
    "\n",
    "    # Allocate event stream to prefix bin class\n",
    "    if 'True label' not in x.keys():\n",
    "        if caseid not in list(case_dict.keys()):\n",
    "            case_bin.set_prefix_length(1)    \n",
    "            case_dict[caseid] = []\n",
    "        else:\n",
    "            case_bin.set_prefix_length(len(case_dict[caseid])+1)\n",
    "            case_bin.set_prev_enc(case_dict[caseid][-1])\n",
    "        case_bin.update_encoded()\n",
    "        case_dict[caseid].append(case_bin)\n",
    "\n",
    "    # Adding newly finished case to training set.    \n",
    "    else:\n",
    "        casecount +=1\n",
    "\n",
    "        # Grace period to collect feature matrix\n",
    "        if casecount <100:\n",
    "            case_length = len(case_dict[caseid])\n",
    "            for prefix in range(1, case_length):\n",
    "                if 'prefix_%s'%(prefix+1) not in list(feature_matrix.keys()):\n",
    "                    feature_matrix['prefix_%s'%(prefix+1)]=set()\n",
    "                    # Initialize classifier and performance matrix and updating count\n",
    "                    trainset_prefix['prefix_%s'%(prefix+1)] = [tree.ExtremelyFastDecisionTreeClassifier(grace_period=10,split_criterion='info_gain'),metrics.Accuracy(), 0]\n",
    "                feature_list = list(case_dict[caseid][prefix].encoded.keys())\n",
    "                for x in feature_list: feature_matrix['prefix_%s'%(prefix+1)].add(x) \n",
    "            case_dict.pop(caseid)               \n",
    "\n",
    "        # Real training start\n",
    "        else:\n",
    "            # Modify encoded attributes of cases with feature matrix\n",
    "            case_length = len(case_dict[caseid])\n",
    "            y = x['True label']\n",
    "            for prefix in range(1, case_length):\n",
    "                case_dict[caseid][prefix].update_truelabel(y)\n",
    "                if case_dict[caseid][prefix].grace_updated == False:\n",
    "                    case_dict[caseid][prefix].encoded = utils.readjustment_training(case_dict[caseid][prefix].encoded, feature_matrix['prefix_%s'%(prefix+1)])\n",
    "                case_dict[caseid][prefix].update_grace_status(True)\n",
    "                x = case_dict[caseid][prefix].encoded\n",
    "                model = trainset_prefix['prefix_%s'%(prefix+1)][0]\n",
    "                model.learn_one(x,y)\n",
    "                trainset_prefix['prefix_%s'%(prefix+1)][2] +=1\n",
    "                y_pred = model.predict_one(x)\n",
    "                trainset_prefix['prefix_%s'%(prefix+1)][1].update(y,y_pred)\n",
    "\n",
    "                for cases in list(case_dict.keys()):\n",
    "                    if len(case_dict[cases]) >prefix:\n",
    "                        if case_dict[cases][prefix].grace_updated ==False:\n",
    "                            case_dict[cases][prefix].encoded = utils.readjustment_training(case_dict[cases][prefix].encoded, feature_matrix['prefix_%s'%(prefix+1)])\n",
    "                        \n",
    "                        case_dict[cases][prefix].update_grace_status(True)\n",
    "                        x_test = case_dict[cases][prefix].encoded\n",
    "                        y_pred = model.predict_one(x_test)\n",
    "                        case_dict[cases][prefix].update_prediction((trainset_prefix['prefix_%s'%(prefix+1)][2], y_pred))\n",
    "            resultdict[caseid] = case_dict.pop(caseid)\n",
    "\n",
    "    if casecount > 200 and rowcounter%1000 == 0:\n",
    "        for prefix in trainset_prefix.keys():\n",
    "            model = trainset_prefix[prefix][0]\n",
    "            if prefix not in list(acc_dict.keys()):\n",
    "                acc_dict[prefix]=[trainset_prefix[prefix][1].get()]\n",
    "            else:\n",
    "                acc_dict[prefix].append(trainset_prefix[prefix][1].get())\n",
    "            outputfile = './%s/%s.png'%(prefix, round(rowcounter*100/totallength,2))\n",
    "            utils.save_graph_as_png(model.draw(),outputfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in acc_dict.keys():\n",
    "    print(acc_dict[prefix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-thing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for prefix in acc_dict.keys():\n",
    "    plt.plot(range(len(acc_dict[prefix])), acc_dict[prefix],label='prefix_%s'%(prefix))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "testcases =[]\n",
    "testpred = []\n",
    "testtrue = []\n",
    "for cases in (np.random.choice(list(resultdict.keys()), 1500)):\n",
    "    if len(resultdict[cases])>3:\n",
    "        y_pred = trainset_prefix['prefix_4'][0].predict_one(resultdict[cases][3].encoded)\n",
    "        testpred.append(y_pred)\n",
    "        testtrue.append(resultdict[cases][3].true_label)\n",
    "metric = metrics.Accuracy()\n",
    "cm = metrics.ConfusionMatrix()\n",
    "for yt,yp in zip(testtrue,testpred):\n",
    "    metric = metric.update(yt,yp)\n",
    "    cm = cm.update(yt,yp)\n",
    "print(metric)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-worthy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
