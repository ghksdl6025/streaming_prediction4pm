{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import practice\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_prefix(df,prefix):\n",
    "    '''\n",
    "    Filter case by prefix length\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Assigned dataframe to slice by prefix length\n",
    "    \n",
    "    prefix : int\n",
    "        Prefix length to slice to cases in fixed length\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Return dataframe with sliced cases\n",
    "    '''\n",
    "    df['ts'] = pd.to_datetime(df['ts'])\n",
    "    groups = df.groupby('caseid')\n",
    "    encoded_df=[]\n",
    "    for case,group in groups: \n",
    "        group = group.reset_index(drop=True)\n",
    "        if len(group)>=prefix:\n",
    "            group = group.loc[:prefix-1,:]\n",
    "            encoded_df.append(group)\n",
    "    return pd.concat(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregation_encoding(df, prefix):\n",
    "    '''\n",
    "    Aggregation encoding\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Assigned dataframe to encode for outcome prediction\n",
    "    \n",
    "    prefix : int\n",
    "        Prefix length to slice to cases in fixed length\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Return dataframe encoded in aggregation method\n",
    "    '''\n",
    "    df = filter_by_prefix(df,prefix)\n",
    "    df['ts'] = pd.to_datetime(df['ts'])\n",
    "    groups = df.groupby('caseid')\n",
    "    encoded_df=[]\n",
    "    for case,group in groups: \n",
    "        group = group.reset_index(drop=True)\n",
    "        outcome = set(group['outcome']).pop()\n",
    "        cumdurationlist = [(x - list(group['ts'])[0]).total_seconds() for x in list(group['ts'])]\n",
    "        case_time_outcome = {'caseid':case, 'ts':np.mean(cumdurationlist),'outcome':outcome}\n",
    "        activity_count = {x: list(group['activity']).count(x) for x in set(group['activity'])}\n",
    "        resource_count = {x: list(group['resource']).count(x) for x in set(group['resource'])}\n",
    "\n",
    "        case_time_outcome.update(activity_count)\n",
    "        case_time_outcome.update(resource_count)\n",
    "        dfk = pd.DataFrame.from_dict([case_time_outcome])\n",
    "        encoded_df.append(dfk)\n",
    "    concated_df = pd.concat(encoded_df)\n",
    "    concated_df = concated_df.fillna(0)\n",
    "    return concated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/bpic2017.csv')\n",
    "df['Complete Timestamp'] = pd.to_datetime(df['Complete Timestamp'])\n",
    "df = df.rename(columns={'Case ID':'caseid','Activity':'activity','Complete Timestamp':'ts','Resource':'resource'})\n",
    "df = df.loc[:,['caseid','activity','ts','resource']]\n",
    "groups = df.groupby('caseid')\n",
    "reconcatenate =[]\n",
    "for _,group in groups:\n",
    "    group = group.reset_index(drop=True)\n",
    "    case_label = practice.set_label(group.iloc[-1,:].to_dict())['True label']\n",
    "    group.loc[:,'outcome'] = case_label\n",
    "    reconcatenate.append(group)\n",
    "dfn = pd.concat(reconcatenate)\n",
    "df2 = aggregation_encoding(dfn,2)\n",
    "df3 = aggregation_encoding(dfn,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              caseid         ts    outcome  O_Create Offer  \\\n0   Offer_1000681710   7.460667   Accepted               1   \n0   Offer_1001553250   5.949333   Accepted               1   \n0   Offer_1002136393   7.380667   Accepted               1   \n0   Offer_1002236598   4.628667    Refused               1   \n0   Offer_1002530118   7.483333  Cancelled               1   \n..               ...        ...        ...             ...   \n0    Offer_993689039   6.695667  Cancelled               1   \n0    Offer_993800442   7.780333  Cancelled               1   \n0     Offer_99473283  89.098333   Accepted               1   \n0    Offer_995784215   7.004333   Accepted               1   \n0    Offer_997411923  12.050667   Accepted               1   \n\n    O_Sent (mail and online)  O_Created  User_20  User_2  User_85  User_49  \\\n0                        1.0          1      3.0     0.0      0.0      0.0   \n0                        1.0          1      0.0     3.0      0.0      0.0   \n0                        1.0          1      0.0     0.0      3.0      0.0   \n0                        1.0          1      0.0     0.0      0.0      3.0   \n0                        1.0          1      0.0     0.0      0.0      0.0   \n..                       ...        ...      ...     ...      ...      ...   \n0                        1.0          1      0.0     0.0      0.0      0.0   \n0                        1.0          1      0.0     0.0      0.0      0.0   \n0                        1.0          1      0.0     0.0      0.0      0.0   \n0                        1.0          1      0.0     0.0      0.0      0.0   \n0                        1.0          1      0.0     0.0      0.0      0.0   \n\n    ...  User_101  User_76  User_119  User_117  User_99  User_112  User_100  \\\n0   ...       0.0      0.0       0.0       0.0      0.0       0.0       0.0   \n0   ...       0.0      0.0       0.0       0.0      0.0       0.0       0.0   \n0   ...       0.0      0.0       0.0       0.0      0.0       0.0       0.0   \n0   ...       0.0      0.0       0.0       0.0      0.0       0.0       0.0   \n0   ...       0.0      0.0       0.0       0.0      0.0       0.0       0.0   \n..  ...       ...      ...       ...       ...      ...       ...       ...   \n0   ...       0.0      0.0       0.0       0.0      0.0       0.0       0.0   \n0   ...       0.0      0.0       0.0       0.0      0.0       0.0       0.0   \n0   ...       0.0      0.0       0.0       0.0      0.0       0.0       0.0   \n0   ...       0.0      0.0       0.0       0.0      0.0       0.0       0.0   \n0   ...       0.0      0.0       0.0       0.0      0.0       0.0       0.0   \n\n    User_116  User_30  User_113  \n0        0.0      0.0       0.0  \n0        0.0      0.0       0.0  \n0        0.0      0.0       0.0  \n0        0.0      0.0       0.0  \n0        0.0      0.0       0.0  \n..       ...      ...       ...  \n0        0.0      0.0       0.0  \n0        0.0      0.0       0.0  \n0        0.0      0.0       0.0  \n0        0.0      0.0       0.0  \n0        0.0      0.0       0.0  \n\n[5000 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BPIC2017 aggregation encoding with prefix length 3\nDecision Tree\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'decision_tree_model' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4f6381dabd57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Deicision tree result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Decision Tree'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecision_tree_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'decision_tree_model' is not defined"
     ]
    }
   ],
   "source": [
    "print('BPIC2017 aggregation encoding with prefix length 3')\n",
    "y = df3['outcome']\n",
    "x =df3.drop(columns=['outcome','caseid'],axis=1)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.3)\n",
    "\n",
    "# Deicision tree result\n",
    "print('Decision Tree')\n",
    "dt = DecisionTreeClassifier(criterion='entropy', max_depth=5).fit(x_train,y_train)\n",
    "y_pred = dt.predict(x_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ]
}