{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import utils\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_prefix(df,prefix):\n",
    "    '''\n",
    "    Filter case by prefix length\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Assigned dataframe to slice by prefix length\n",
    "    \n",
    "    prefix : int\n",
    "        Prefix length to slice to cases in fixed length\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Return dataframe with sliced cases\n",
    "    '''\n",
    "    df['ts'] = pd.to_datetime(df['ts'])\n",
    "    groups = df.groupby('caseid')\n",
    "    encoded_df=[]\n",
    "    for case,group in groups: \n",
    "        group = group.reset_index(drop=True)\n",
    "        if len(group)>prefix:\n",
    "            group = group.loc[:prefix-1,:]\n",
    "            encoded_df.append(group)\n",
    "    return pd.concat(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregation_encoding(df, prefix):\n",
    "    '''\n",
    "    Aggregation encoding\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Assigned dataframe to encode for outcome prediction\n",
    "    \n",
    "    prefix : int\n",
    "        Prefix length to slice to cases in fixed length\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Return dataframe encoded in aggregation method\n",
    "    '''\n",
    "    df = filter_by_prefix(df,prefix)\n",
    "    df['ts'] = pd.to_datetime(df['ts'])\n",
    "    groups = df.groupby('caseid')\n",
    "    encoded_df=[]\n",
    "    for case,group in groups: \n",
    "        group = group.reset_index(drop=True)\n",
    "        outcome = set(group['outcome']).pop()\n",
    "        cumdurationlist = [(x - list(group['ts'])[0]).total_seconds() for x in list(group['ts'])]\n",
    "        case_time_outcome = {'caseid':case, 'ts':np.mean(cumdurationlist),'outcome':outcome}\n",
    "        activity_count = {x: list(group['activity']).count(x) for x in set(group['activity'])}\n",
    "        resource_count = {x: list(group['resource']).count(x) for x in set(group['resource'])}\n",
    "\n",
    "        case_time_outcome.update(activity_count)\n",
    "        case_time_outcome.update(resource_count)\n",
    "        dfk = pd.DataFrame.from_dict([case_time_outcome])\n",
    "        encoded_df.append(dfk)\n",
    "    concated_df = pd.concat(encoded_df)\n",
    "    concated_df = concated_df.fillna(0)\n",
    "    return concated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexbase_encoding(df, prefix):\n",
    "    '''\n",
    "    Indexbase encoding\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Assigned dataframe to encode for outcome prediction\n",
    "    \n",
    "    prefix : int\n",
    "        Prefix length to slice to cases in fixed length\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Return dataframe encoded in indexbase method\n",
    "    '''\n",
    "    df = filter_by_prefix(df,prefix)\n",
    "    df['ts'] = pd.to_datetime(df['ts'])\n",
    "    groups = df.groupby('caseid')\n",
    "    encoded_df=[]\n",
    "    for case,group in groups: \n",
    "        activitylist = list(group['activity'])\n",
    "        resourcelist = list(group['resource'])\n",
    "        group = group.reset_index(drop=True)\n",
    "        outcome = set(group['outcome']).pop()\n",
    "        cumdurationlist = [(x - list(group['ts'])[0]).total_seconds() for x in list(group['ts'])]\n",
    "        cumduration_index ={'Cumduration_'+str(x+1): cumdurationlist[x] for x in range(len(cumdurationlist))}\n",
    "        case_outcome = {'caseid':case, 'outcome':outcome}\n",
    "        activity_index = {'activity_'+str(x+1)+'_'+activitylist[x]: 1 for x in range(len(activitylist))}\n",
    "        resource_index = {'resource_'+str(x+1)+'_'+str(resourcelist[x]): 1 for x in range(len(resourcelist))}\n",
    "        case_outcome.update(cumduration_index)\n",
    "        case_outcome.update(activity_index)\n",
    "        case_outcome.update(resource_index)\n",
    "        dfk = pd.DataFrame.from_dict([case_outcome])\n",
    "        encoded_df.append(dfk)\n",
    "    concated_df = pd.concat(encoded_df)\n",
    "    concated_df = concated_df.fillna(0)\n",
    "    return concated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/bac_online_small.csv')\n",
    "df['START_DATE'] = pd.to_datetime(df['START_DATE'])\n",
    "df = df.rename(columns={'REQUEST_ID':'caseid','ACTIVITY':'activity','START_DATE':'ts','CE_UO':'resource'})\n",
    "df = df.loc[:,['caseid','activity','ts','resource','outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby('caseid')\n",
    "concating = []\n",
    "for _, group in groups:\n",
    "    outcomelist = list(group['outcome'])\n",
    "    outcome = outcomelist[-1]\n",
    "    group = group.reset_index(drop=True)\n",
    "    if True in outcomelist:\n",
    "        group = group.loc[:outcomelist.index(True),:]\n",
    "    group['outcome'] = outcome\n",
    "    concating.append(group)\n",
    "\n",
    "dfn = pd.concat(concating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf10 = aggregation_encoding(dfn,10)\n",
    "idf10 = indexbase_encoding(dfn,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf5 = aggregation_encoding(dfn,5)\n",
    "idf5 = indexbase_encoding(dfn,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf6 = aggregation_encoding(dfn,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf7 = aggregation_encoding(dfn,7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf8 = aggregation_encoding(dfn,8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf9 = aggregation_encoding(dfn,9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf11 = aggregation_encoding(dfn,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf2 = aggregation_encoding(dfn,2)\n",
    "adf3 = aggregation_encoding(dfn,3)\n",
    "adf4 = aggregation_encoding(dfn,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAC aggregation encoding with prefix length 5\n",
      "Decision Tree\n",
      "0.9227251943301326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.98      0.96      2006\n",
      "        True       0.55      0.34      0.42       181\n",
      "\n",
      "    accuracy                           0.92      2187\n",
      "   macro avg       0.75      0.66      0.69      2187\n",
      "weighted avg       0.91      0.92      0.91      2187\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      1.00      0.96      2006\n",
      "        True       0.00      0.00      0.00       181\n",
      "\n",
      "    accuracy                           0.92      2187\n",
      "   macro avg       0.46      0.50      0.48      2187\n",
      "weighted avg       0.84      0.92      0.88      2187\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suhwan/.conda/envs/testenv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('BAC aggregation encoding with prefix length 5')\n",
    "y = adf5['outcome']\n",
    "x =adf5.drop(columns=['outcome','caseid'],axis=1)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.3)\n",
    "\n",
    "# Deicision tree result\n",
    "print('Decision Tree')\n",
    "dt = DecisionTreeClassifier(criterion='entropy', max_depth=5).fit(x_train,y_train)\n",
    "y_pred = dt.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "rf = RandomForestClassifier(criterion='entropy', max_depth=5).fit(x_train,y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAC aggregation encoding with prefix length 2\n",
      "BAC aggregation encoding with prefix length 3\n",
      "BAC aggregation encoding with prefix length 4\n",
      "BAC aggregation encoding with prefix length 5\n",
      "BAC aggregation encoding with prefix length 6\n",
      "BAC aggregation encoding with prefix length 7\n",
      "BAC aggregation encoding with prefix length 8\n",
      "BAC aggregation encoding with prefix length 9\n",
      "BAC aggregation encoding with prefix length 10\n",
      "BAC aggregation encoding with prefix length 11\n"
     ]
    }
   ],
   "source": [
    "adflist = [adf2,adf3,adf4,adf5,adf6,adf7,adf8,adf9,adf10,adf11]\n",
    "prefixlist= list(range(2,12))\n",
    "acc_dict= {}\n",
    "for pos,prefix in enumerate(adflist):\n",
    "    print('BAC aggregation encoding with prefix length %s'%(prefixlist[pos]))\n",
    "    y = prefix['outcome']\n",
    "    x =prefix.drop(columns=['outcome','caseid'],axis=1)\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.3)\n",
    "\n",
    "    # Deicision tree result\n",
    "    dt = DecisionTreeClassifier(criterion='entropy').fit(x_train,y_train)\n",
    "    y_pred = dt.predict(x_test)\n",
    "    acc_dict['prefix_%s'%(str(prefixlist[pos]))] =  accuracy_score(y_test,y_pred)\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "x = list(acc_dict.keys())\n",
    "y = [acc_dict[x] for x in acc_dict.keys()]\n",
    "with open('./result/off_dt_acc.pkl','wb') as f:\n",
    "    pkl.dump([x,y],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAC aggregation encoding with prefix length 2\n",
      "BAC aggregation encoding with prefix length 3\n",
      "BAC aggregation encoding with prefix length 4\n",
      "BAC aggregation encoding with prefix length 5\n",
      "BAC aggregation encoding with prefix length 6\n",
      "BAC aggregation encoding with prefix length 7\n",
      "BAC aggregation encoding with prefix length 8\n",
      "BAC aggregation encoding with prefix length 9\n",
      "BAC aggregation encoding with prefix length 10\n",
      "BAC aggregation encoding with prefix length 11\n"
     ]
    }
   ],
   "source": [
    "adflist = [adf2,adf3,adf4,adf5,adf6,adf7,adf8,adf9,adf10,adf11]\n",
    "prefixlist= list(range(2,12))\n",
    "acc_dict= {}\n",
    "for pos,prefix in enumerate(adflist):\n",
    "    print('BAC aggregation encoding with prefix length %s'%(prefixlist[pos]))\n",
    "    y = prefix['outcome']\n",
    "    x =prefix.drop(columns=['outcome','caseid'],axis=1)\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.3)\n",
    "\n",
    "    # Deicision tree result\n",
    "    dt = RandomForestClassifier(criterion='entropy').fit(x_train,y_train)\n",
    "    y_pred = dt.predict(x_test)\n",
    "    acc_dict['prefix_%s'%(str(prefixlist[pos]))] =  accuracy_score(y_test,y_pred)\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "x = list(acc_dict.keys())\n",
    "y = [acc_dict[x] for x in acc_dict.keys()]\n",
    "with open('./result/off_rf_acc.pkl','wb') as f:\n",
    "    pkl.dump([x,y],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
